ID         = $(Process)
NAME       = mbl
universe   = vanilla
executable = ../build/Release/DMRG++
arguments  = $(inputfiles)
requirements = true

########################################################
# List your CPU, MEMORY and DISK requirements below.
# Note that numeric requirements are not enclosed by "".
# * cpus are the number of condor "slots"
# * memory in units of MB
# * disk in units of MB
# Note that requiring two on single threaded jobs
# essentially turns off hyperthreading.
########################################################
request_cpus   = 1
request_memory = 3000
request_disk   = 400



########################################################
# List your requirements below. Uncomment to activate.
# Note that numeric requirements are not enclosed by "".
########################################################
requirements = $(requirements) && TARGET.OpSysAndVer    == "Ubuntu18"
#requirements = $(requirements) && TARGET.OpSysName      == "Ubuntu"
#requirements = $(requirements) && TARGET.OpSysMajorVer  == 18
#requirements = $(requirements) && TARGET.Arch           == "X86_64"
#requirements = $(requirements) && TARGET.OpSys          == "LINUX"




########################################################
# In this cluster you can chose any of the main
# microarchitecture families by requiring
# TARGET.CpuMarch_<ARCH> == true.
# Read more about the CPU microarchitechtures here:
# https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures
# Find your microarchitecture with the following command:
#     gcc-8 -march=native -Q --help=target|grep march
#
# In order of old -> new:
# CpuMarch_CORE2        includes core2 processors like Penryn
# CpuMarch_NEHALEM      includes Westmere
# CpuMarch_SANDYBRIDGE  includes Ivybridge
# CpuMarch_HASWELL      includes Broadwell
# CpuMarch_SKYLAKE      includes Kaby, Coffee, Cannon, Cascade and Cooper Lake
########################################################

requirements = $(requirements) && \
                TARGET.CpuMarch_NEHALEM == true




#########################################################
# Use lines below when there is no shared NFS filesystem
#########################################################
#should_transfer_files = yes
#when_to_transfer_output = on_exit_or_evict
#transfer_input_files = $(inputfiles)
#transfer_output_files = output/
#transfer_output_remaps = "output.h5 = ../output/output_$(ID).h5"


###############################################################################################
# getenv = True will copy the environment variables of the submit machines to the other nodes
# environment = "myvar=someval" will set the environment variable at the node
# Note that file locking is not working on NFS so you must disable it on HDF5.
# Do that with
#               environment = "HDF5_USE_FILE_LOCKING=FALSE"
################################################################################################
#environment = "HDF5_USE_FILE_LOCKING=FALSE"

getenv = true


log        = logs/$(NAME)_$(ID).log
output     = logs/$(NAME)_$(ID).out
error      = logs/$(NAME)_$(ID).error
queue inputfiles matching files input/L_24/$(NAME)_*.cfg
