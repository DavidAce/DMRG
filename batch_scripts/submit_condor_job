ID         = $(Process)
NAME       = mbl
universe   = vanilla
executable = ../build/Release/DMRG++
arguments  = $(inputfiles)
requirements = true

########################################################
# List your CPU, MEMORY and DISK requirements below.
# Note that numeric requirements are not enclosed by "".
# * cpus are the number of condor "slots"
# * memory in units of MB
# * disk in units of MB
# Note that requiring two on single threaded jobs
# essentially turns off hyperthreading.
########################################################
request_cpus   = 1
request_disk   = 500
request_memory = 2000

#################################################################################
# The below lines added to the submit file will allow the jobs to
# self-police MemoryUsage, and will adjust the memory request in response
# (though "request_memory" would need to be replaced in the submit file, not
# added).
# These lines essentially say:
# Set the "request_memory" ("RequestMemory" in the job classad) to be a
# function of MemoryUsage, and artificially set the MemoryUsage to an initial
# value (800 MB * 2/3).
# Put the job on hold if the (real) MemoryUsage goes 50% above the current
# RequestMemory value.
# Release the held job (if held for the memory reason, and held for at least
# 3 minutes), so that it will be matched to run again on a compute "slot"
# with more memory (according to the new RequestMemory value).
##################################################################################
# +MemoryUsage     = ( 3000 ) * 2 / 3
# request_memory   = ( MemoryUsage ) * 3 / 2
# periodic_hold    = ( MemoryUsage >= ( ( RequestMemory ) * 3 / 2 ) )
# periodic_release = (JobStatus == 5) && ((CurrentTime - EnteredCurrentStatus) > 180) && (HoldReasonCode != 34)




########################################################
# List your requirements below. Uncomment to activate.
# Note that numeric requirements are not enclosed by "".
########################################################
#requirements = $(requirements) && TARGET.OpSysAndVer    == "Ubuntu18"
#requirements = $(requirements) && TARGET.OpSysName      == "Ubuntu"
#requirements = $(requirements) && TARGET.OpSysMajorVer  == 18
#requirements = $(requirements) && TARGET.Arch           == "X86_64"
#requirements = $(requirements) && TARGET.OpSys          == "LINUX"




########################################################
# In this cluster you can chose any of the main
# microarchitecture families by requiring
# TARGET.CpuMarch_<ARCH> == true.
# Read more about the CPU microarchitechtures here:
# https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures
# Find your microarchitecture with the following command:
#     gcc-8 -march=native -Q --help=target|grep march
#
# In order of old -> new:
# CpuMarch_CORE2        includes core2 processors like Penryn
# CpuMarch_NEHALEM      includes Westmere
# CpuMarch_SANDYBRIDGE  includes Ivybridge
# CpuMarch_HASWELL      includes Broadwell
# CpuMarch_SKYLAKE      includes Kaby, Coffee, Cannon, Cascade and Cooper Lake
########################################################

requirements = $(requirements) && \
                TARGET.CpuMarch_SANDYBRIDGE == true


#requirements = $(requirements) && \
#                TARGET.has_avx == true
#


requirements = $(requirements) && \
                TARGET.Machine == "turing"



#########################################################
# Use lines below when there is no shared NFS filesystem
#########################################################
#should_transfer_files = yes
#when_to_transfer_output = on_exit_or_evict
#transfer_input_files = $(inputfiles)
#transfer_output_files = output/
#transfer_output_remaps = "output.h5 = ../output/output_$(ID).h5"


###############################################################################################
# getenv = True will copy the environment variables of the submit machines to the other nodes
# environment = "myvar=someval" will set the environment variable at the node
# Note that file locking is not working on NFS so you must disable it on HDF5.
# Do that with
#               environment = "HDF5_USE_FILE_LOCKING=FALSE"
################################################################################################
#environment = "HDF5_USE_FILE_LOCKING=FALSE"

getenv = true


log        = logs/$(NAME)_$(ID).log
output     = logs/$(NAME)_$(ID).out
error      = logs/$(NAME)_$(ID).error

# queue inputfiles matching files input/L_*/$(NAME)_*.cfg

# queue inputfiles matching files input/L_12/$(NAME)_*.cfg
# queue inputfiles matching files input/L_16/$(NAME)_*.cfg
# queue inputfiles matching files input/L_20/$(NAME)_*.cfg
queue inputfiles matching files input/L_24/$(NAME)_*.cfg
# queue inputfiles matching files input/L_28/$(NAME)_*.cfg
# queue inputfiles matching files input/L_32/$(NAME)_*.cfg
# queue inputfiles matching files input/L_36/$(NAME)_*.cfg

